#!/bin/bash

# Enhanced GodMode Dashboard Deployment Script
# Sets up the enhanced NovaOS GodMode dashboard with LLM integration

set -e

echo "ğŸš€ Deploying Enhanced GodMode Dashboard..."

# Check if we're in the right directory
if [ ! -f "docker-compose.yml" ]; then
    echo "âŒ Error: This script must be run from the NovaOS-Core-Systems root directory"
    exit 1
fi

# Set environment variables for enhanced mode
export ENHANCED_GODMODE=true
export NODE_ENV=${NODE_ENV:-development}

echo "ğŸ“¦ Installing dependencies..."

# Install any missing dependencies (if needed in the future)
# pnpm install --filter novaos lucide-react

echo "ğŸ”„ Building NovaOS app with enhanced features..."
cd apps/novaos
pnpm build
cd ../..

echo "ğŸ§  Checking LLM integration status..."

# Check if LLM services are configured
if [ -f "ai_models/llm_config.json" ]; then
    echo "âœ… LLM configuration found"
else
    echo "âš ï¸  LLM configuration not found - some features may be limited"
fi

# Check if Ollama is running (optional)
if command -v ollama &> /dev/null && ollama list &> /dev/null; then
    echo "âœ… Ollama is available"
else
    echo "â„¹ï¸  Ollama not detected - will use other LLM providers if configured"
fi

echo "ğŸ³ Restarting services with enhanced configuration..."

# Restart the NovaOS service to pick up changes
docker-compose up -d novaos

# Wait for service to be ready
echo "â³ Waiting for services to be ready..."
sleep 10

# Check service health
echo "ğŸ” Checking service health..."

# Test the NovaOS app
if curl -f -s http://localhost:3002/api/health > /dev/null 2>&1; then
    echo "âœ… NovaOS service is healthy"
else
    echo "âš ï¸  NovaOS service health check failed - may still be starting"
fi

# Test the LLM proxy endpoints
if curl -f -s http://localhost:3002/api/llm/health > /dev/null 2>&1; then
    echo "âœ… LLM integration endpoints are working"
else
    echo "â„¹ï¸  LLM endpoints not responding - check core-api service"
fi

echo ""
echo "ğŸ‰ Enhanced GodMode Dashboard deployment completed!"
echo ""
echo "ğŸ“ Access your enhanced dashboard at:"
echo "   ğŸŒ http://localhost:3002/godmode"
echo ""
echo "âœ¨ New features available:"
echo "   â€¢ Real-time agent monitoring with health status"
echo "   â€¢ Direct agent command execution interface"
echo "   â€¢ Integrated LLM chat with streaming responses"
echo "   â€¢ Multi-provider LLM support (OpenAI, Ollama, LM Studio)"
echo "   â€¢ Enhanced agent grid with live capabilities display"
echo "   â€¢ Advanced agent management console"
echo ""
echo "ğŸ”§ Configuration:"
echo "   â€¢ Enhanced mode: $ENHANCED_GODMODE"
echo "   â€¢ Environment: $NODE_ENV"
echo "   â€¢ LLM Integration: $([ -f "ai_models/llm_config.json" ] && echo "Configured" || echo "Limited")"
echo ""
echo "ğŸ’¡ Pro tip: Enable the 'enhanced_godmode' feature flag in the dashboard"
echo "   for persistent enhanced mode across all sessions."
echo ""

# Optional: Open browser (if on desktop environment)
if command -v xdg-open &> /dev/null; then
    echo "ğŸŒ Opening enhanced dashboard in browser..."
    xdg-open http://localhost:3002/godmode
elif command -v open &> /dev/null; then
    echo "ğŸŒ Opening enhanced dashboard in browser..."
    open http://localhost:3002/godmode
fi

echo "âœ… Deployment completed successfully!"
